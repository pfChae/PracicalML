---
title: "PML_project"
author: "Hwa Sung Chae"
date: '2021 6 8 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

To address the project, I chose 'Random forest' to predict the test set. Beforehand, I also measured the accuracy of 'Decision tree' and 'generalized boosted model.' Since 'Random forest' demonstrated the best accuracy (0.9997), I selected this model. 

A summary of building up the model.

1) The crossvalidation was performed using 25% of the training sample to evaluate the overfitting.  

2) Apply random forest to the train, and crossvallidation samples and evaluation 

3) Perform test sample prediction 

4) Find the important variables using 'importance' function. 

## Download packages

```{r}
install.packages("caret") ;require(caret)
install.packages("randomForest") ; library("randomForest")
install.packages("e1071")
library(e1071)
```
## DATA Loading, remove NA columns for the training and testing data
```{r}
traindata <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testdata  <- read.csv("pml-testing.csv", na.strings = c("NA", "#DIV/0!", ""))
comps <- complete.cases(t(traindata)) & complete.cases(t(testdata))
traindata1 <- traindata[,comps]
testdata1  <- testdata[,comps]
# Drop the first 7 columns as they're unnecessary for predicting.
traindata2<- traindata1[,8:length(colnames(traindata1))]
testdata2 <- testdata1[,8:length(colnames(testdata1))]
```
## Cross Validation

```{r}
set.seed(32323)
in.training <- createDataPartition(traindata2$classe, p=0.75, list=F)
Train <- traindata2[in.training, ]
Cross <- traindata2[-in.training, ]
Train$classe = as.factor(Train$classe)
```
## Modeling

```{r}
modFit <- randomForest(Train$classe~., data = Train, importance=T)
modFit    #Please, take time. It may takes a few minitues:) #
testdata2$classe = as.factor(testdata2$classe)
pred1 <-predict(modFit,Train)
table(pred1)
table(Train$classe)
confusionMatrix(pred1,Train$classe) #Accuray : 0.9997
```
## The results on the validation set

```{r}
Cross$classe = as.factor(Cross$classe)
valid <- predict(modFit, newdata=Cross)
confusionMatrix(valid,Cross$classe)  #Accuracy : 0.9951
```
## The results on the test set
```{r}
testresults <- predict(modFit, newdata=testdata2)
print("Classifications on the test set:"); testresults
```
## Importance of the variables
```{r}
varImp <- importance(modFit)
varImp[1:10,]
```
In conclusion, 'Random Forest' in this model conducted an accurate prediction entirely.  The importance of the variables revealed that yaw_belt, rell_ belt, and pitch_belt  are the essential variables in sequence and the upper ten variables seem to decide the classification. After testing 'Course project prediction quiz', I was sure the model is completely accurate. 

## Appendix, Plot

```{r pressure, echo=FALSE}
varImpPlot(modFit, type = 1)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

